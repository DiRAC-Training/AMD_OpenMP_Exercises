{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a8cbf7-16be-4daf-b4ad-3eda4ea637ba",
   "metadata": {},
   "source": [
    "# Device functions and subroutines in Fortran\n",
    "\n",
    "Until now, we have focused on how to offload data or particular calculations to the GPU.\n",
    "In most real software applications, however, we will want to pass data through a pipeline of multiple subroutines and submodules before completion.\n",
    "In this notebook, we will learn how to call subroutines to run on the device from within existing target regions.\n",
    "In so doing, we will combine many of the things we have learned up to this point, and let you try porting some code to the GPU using OpenMP yourself.\n",
    "\n",
    "Let's begin as usual with our environment check and moving into the appropriate directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa63f02-91b4-4ca7-bdf1-bf65552ebb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocm-smi\n",
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2g-OpenMP_device_subroutines/Fortran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2e0f4-871e-4c57-ace0-d93e80ac76f5",
   "metadata": {},
   "source": [
    "## The `declare target` clause\n",
    "\n",
    "Calling a subroutine that has been compiled for the architecture of the host from within a target region can have unexpected consequences.\n",
    "It may not be able to run on the device architecture, and in some compilers may even cause a linking error.\n",
    "To ensure that our subroutines can run on the device, we must indicate to the compiler that a device-compatible version should be generated.\n",
    "We can do this adding a `declare target` clause to the subroutines definition, immediately after the standard `implicit none` clause.\n",
    "It is also possible to pre-declare a range of target subroutines using `declare target(func-list)` before the subroutine definitions, with the names of the target subroutines in question as a comma separated `func-list`.\n",
    "\n",
    "To get started, let's move into our first example directory, `device_routine_with_interface/0_device_routine_portyourself`, and clean our environment therein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad7ec9-b82c-4e50-a2a4-dd74868654c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2g-OpenMP_device_subroutines/Fortran/device_routine_with_interface/0_device_routine_portyourself\n",
    "make clean\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e42d6-a8d2-42b3-a9a0-489f160a6a49",
   "metadata": {},
   "source": [
    "There are 2 files in the source code; [`device_routine.f90`](./Fortran/device_routine_with_interface/0_device_routine_portyourself/device_routine.f90) where `program device_routine` is implemented, and [`compute.f90`](./Fortran/device_routine_with_interface/0_device_routine_portyourself/compute.f90) where the `compute()` subroutine is implemented.\n",
    "At the moment, this code will run in serial on the CPU - it is your task to implement the appropriate OpenMP pragmas to get it running properly on the GPU.\n",
    "\n",
    "Before porting the code, read the source code and try to understand it.\n",
    "Then, compile and run this baseline CPU version, to know what to expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee69f53-5d11-4c18-8acf-587d70da6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "make\n",
    "./device_routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ad5af-8cb0-4ff6-bba3-e61e49eb9632",
   "metadata": {},
   "source": [
    "To port the code, we can either use managed memory with unified shared memory - which was covered in [2e-OpenMP_managed_memory](./../2e-OpenMP_managed_memory/Managed_memory_in_Fortran.ipynb) - explicit memory movements in the parallel regions with `map` clauses, or unmanaged memory with an unstructured data region - as covered in [2d-OpenMP_explicit_memory_directive](./../2d-OpenMP_explicit_memory_directive/Explicit_memory_management_in_Fortran.ipynb).\n",
    "Note that if using unified shared memory, the function `compute` in [`compute.f90`](./Fortran/device_routine_with_interface/0_device_routine_portyourself/compute.f90) will also need to include the `requires unified_shared_memory` directive, and you must enable `HSA_XNACK`.\n",
    "\n",
    "Make sure you identify all the appropriate parallel regions for offloading, and use the appropriate OpenMP clause for each.\n",
    "One of the regions has a race condition, which you should address with what we learned in [2f-OpenMP_reductions_atomics_mutexes](./../2f-OpenMP_reductions_atomics_mutexes/Reductions_atomics_and_mutexes_in_Fortran.ipynb).\n",
    "Notice that `compute()` is called from within one of the regions, and remember what we discuseed earlier regarding the `declare target` clause.\n",
    "Note that for Fortran, the `!$omp declare target` directive goes inside the subroutine rather than outside, as is done for C functions.\n",
    "\n",
    "You can use the code cell above to compile and run your code as you modify it.\n",
    "After porting the code, you can compare your results with the possible solutions in the subdirectories of `device_routine_with_interface/`.\n",
    "Several solutions are provided, including one 'wrong' solution; the example in `1_device_routine_wrong/` (demonstrated in the code cell below) shows the compilation errors that will be generated when the subroutine is not declared to run on the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129abe82-9e67-46da-9eb8-812867c87e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2g-OpenMP_device_subroutines/Fortran/device_routine_with_interface/1_device_routine_wrong\n",
    "make clean\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1737ef-aca1-4ef8-8f77-d0735b82c808",
   "metadata": {},
   "source": [
    "The managed memory with unified shared memory solution is provided in `2_device_routine_usm/`, the unmanaged memory solution using explicit memory movements is in `3_device_routine_map/`, and the solution using unmanaged memory with an unstructured data region in `5_device_routine_enter_data/`.  \n",
    "\n",
    "There is an additional solution covering an OpenMP clause we have not previously seen, `declare target device_type(nohost)`, in `4_device_routine_device_type/`.\n",
    "This clause tells the compiler that this subroutine needs to be compiled for the device **only**, and not the host.\n",
    "\n",
    "You now may wish to experiment with these different solutions by changing the problem size or the complexity of the calculation in `compute()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140b358-fed3-4719-add2-3396f53f4bb2",
   "metadata": {},
   "source": [
    "## Device routines within modules\n",
    "\n",
    "The next part of this notebook will cover the use of Fortran **modules** - a common way to encapsulate code for reusability, organisation and maintainability.\n",
    "The example code we will be using is in the `device_routine_with_module/0_device_routine_with_module_portyourself/` directory, so let's move to that and examine the contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abf012-5032-43d7-b225-1a5ea7c1a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2g-OpenMP_device_subroutines/Fortran/device_routine_with_module/0_device_routine_with_module_portyourself\n",
    "make clean\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8611658-942b-4c0d-a7a1-6c1ca93a3f5b",
   "metadata": {},
   "source": [
    "There are again two source code files; [device_routine.f90](Fortran/device_routine_with_module/0_device_routine_with_module_portyourself/device_routine.f90) containing the `device_routine` program implementation, and [`computemod.f90`](./Fortran/device_routine_with_module/0_device_routine_with_module_portyourself/computemod.f90), which contains a module that includes the `compute()` subroutine, replacing the `compute.f90` file from the previous exercise.\n",
    "\n",
    "To port a subroutine within a module to the GPU, we need to add the `declare target` clause within the subroutine itself, just as we did with the previous example.\n",
    "The pragma should be applied only to the subroutines that need porting, and should not be applied to the whole module.\n",
    "Conversely, if we want to use unified shared memory, the enabling clause must be applied to the module as a whole, being placed after its declaration at the beginning of the file.\n",
    "\n",
    "The only difference between this code and the previous example is that it encapsulates the subroutine into a module, so we know what to expect from it and can go straight into porting it.\n",
    "You can use the following code block to compile and run the code.\n",
    "If using unified shared memory, remember to add `export HSA_XNACK=1` before running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd0b2a-f340-4c3b-883a-f284f6c07adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "make\n",
    "./device_routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d1ab3a-8d58-43a0-8838-d53a3967b789",
   "metadata": {},
   "source": [
    "Now that you have attempted to port your code, you can compare it with the model solutions.\n",
    "Two versions are provided, one using unmanaged memory with an unstructured data region - see `1_device_routine_with_module/` - and one with unified shared memory - see `2_device_routine_with_module_usm/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c073c70-58ee-46b6-9497-d01871fdf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2g-OpenMP_device_subroutines/Fortran/device_routine_with_module/1_device_routine_with_module\n",
    "make clean\n",
    "make\n",
    "./device_routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fee52d-c040-4f55-9d06-ec01e90b0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2g-OpenMP_device_subroutines/Fortran/device_routine_with_module/2_device_routine_with_module_usm\n",
    "make clean\n",
    "make\n",
    "export HSA_XNACK=1\n",
    "./device_routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b9a03-f698-4dbb-be7f-97f8629d417c",
   "metadata": {},
   "source": [
    "Once you are happy with the solution, feel free to take some time to experiment with the code - perhaps adjusting problem size, changing the complexity, or adding in additional device subroutines to the module - to get a handle on how offloading subroutines works.\n",
    "\n",
    "Throughout this section of the course, we've learnt the fundamentals of OpenMP, and how they can help you run performant code on an AMD GPU or APU.\n",
    "You should now be equipped to start porting your own code to such architectures.\n",
    "\n",
    "There follows an optional section on OpenMP optimisations.\n",
    "Feel free to follow it at your leisure.\n",
    "The next main section of this course will cover HIP programming, and the use of dedicated kernels to improve performance on accelerated devices.\n",
    "Unfortunately, HIP Fortran is still in development and not all features are fully supported, so the notebooks will concentrate instead on C/CXX."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NI200",
   "language": "bash",
   "name": "ni200"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
