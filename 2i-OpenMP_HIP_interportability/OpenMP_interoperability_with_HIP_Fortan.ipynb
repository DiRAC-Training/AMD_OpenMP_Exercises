{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca38bdf",
   "metadata": {},
   "source": [
    "# OpenMP and HIP Interoperability\n",
    "\n",
    "In this notebook, we will see how we can write an application that makes use of both OpenMP pragmas and HIP kernels.\n",
    "This type of strategic use of multiple acceleration paradigms can make our code flexible and performant in ways that would not be possible with just one.\n",
    "\n",
    "Let's begin in the traditional way; by checking that we have an appropraite GPU on the system, loading into the relevant working directory and cleaning our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33000dda-d34b-42cf-84e9-33ad0ad01ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocm-smi\n",
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2i-OpenMP_HIP_interportability/Fortran\n",
    "make clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2fed05",
   "metadata": {},
   "source": [
    "## Why use HIP and OpenMP?\n",
    "\n",
    "As we've learned throughout these notebooks, OpenMP is a flexible and portable pragma-based API for shared-memory parallelism.\n",
    "It allows relatively straightforward parallelism to be implemented across different architectures, but lacks the level of direct control that other paradigms offer.\n",
    "\n",
    "HIP, on the other hand, offers a tighter control at the cost of OpenMP's ease and flexibility.\n",
    "The details of HIP implementation will not be discussed in this notebook - rather, that will be saved for the next section of this course.\n",
    "For now, it is enough to know that it is a low-level language that makes use of kernels to offer a more direct control of the offloaded compute.\n",
    "\n",
    "Both of these approaches have their upsides and their drawbacks, so you might wonder if there was a way to incorporate both into code, to draw on their relative strengths.\n",
    "And you would indeed be correct - there is!\n",
    "Code making use of OpenMP pragmas can call HIP kernels, and HIP applications can call OpenMP kernels.\n",
    "\n",
    "Using this knowledge we can, for example, write our simple loops using OpenMP pragmas, but write our complicated offloaded routines where we require fine-grained control to optimise their performance as HIP kernels.\n",
    "By using both in the same application, we really can have the best of both worlds.\n",
    "\n",
    "Unfortunately, HIP does not have a working implementation in Fortran.\n",
    "Thanks to Fortran's interoperability with C, however, we can still gain its benefits in our code.\n",
    "By writing our HIP kernel in C, we can call it as usual from within our Fortran program.\n",
    "\n",
    "### An example implementation\n",
    "\n",
    "We have an example of an OpenMP-enabled Fortran code calling a HIP kernel available here.\n",
    "Let's look at the files in our current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c941f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344597fd",
   "metadata": {},
   "source": [
    "[`main.F90`](./Fortran/main.F90) is the main Fortran part of the code.\n",
    "In it, we allocate 2 arrays, `x` and `y`, enter a `target data` region that transfers them to the device, then carry out operations on these arrays on the host.\n",
    "These changes are updated to the device with the `update` pragma, and then the external function `daxpy_hip` is called.\n",
    "We leave the `target data` region, carry out a final computation on the host, and exit the program.\n",
    "Note that the `target data` and `update` pragmas are unnecessary on a shared-memory enabled device such as an APU.\n",
    "\n",
    "[`daxpy_kernel.cpp`](./Fortran/daxpy_kernel.cpp) then provides the C implementation of the daxpy HIP kernel called from this file.\n",
    "\n",
    "[`hip_interface.F90`](./Fortran/hip_interface.F90) provides the necessary interface information for Fortran to be able to call this function.\n",
    "\n",
    "[`Makefile`](./Fortran/Makefile) can then be used to build the application.\n",
    "Let's take a look at the [`Makefile`](./Fortran/Makefile) to fully understand how we compile all the necessary parts of this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat Makefile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df755f",
   "metadata": {},
   "source": [
    "We can see that the default build rule calls a number of build instructions:\n",
    " - [`daxpy_kernel.cpp`](./Fortran/daxpy_kernel.cpp) is built using the `hipcc` compiler, in order to import the HIP runtime information,\n",
    " - [`hip_interface.F90`](./Fortran/hip_interface.F90) is built with the AMD Fortran llvm-based compiler `amdflang` to allow the import of the daxpy kernel,\n",
    " - [`main.F90`](./Fortran/main.F90) is built with the the same Fortran compiler as the interface code, but with the OpenMP flags enabled,\n",
    " - The executable is then called by linking these objects together.\n",
    "\n",
    "Let's try compiling and running it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88c39e-dbbb-47c4-8c80-9a552499f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "make daxpy\n",
    "./daxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed2614",
   "metadata": {},
   "source": [
    "If all has worked well, the code will state which machine it was compiled for - the host or the device - and verify that the results were reported correctly.\n",
    "Congratulations!\n",
    "You've now successfully run code with multiple forms of acceleration enabled.\n",
    "\n",
    "This concludes the tutorial's optional lessons on OpenMP.\n",
    "\n",
    "In the next set of notebooks, we will dive in to HIP proper; examining its functionality; discovering the strengths of its programming model; and learning how we can implement it into our code.  As the HIP support for Fortran is still in development, these notebooks will be exclusively in C/C++."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NI200",
   "language": "bash",
   "name": "ni200"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
