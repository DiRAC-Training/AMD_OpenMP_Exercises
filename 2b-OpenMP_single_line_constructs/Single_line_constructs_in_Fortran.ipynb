{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05674623-8358-4dcb-a7d9-2042e1aeceb2",
   "metadata": {},
   "source": [
    "# OpenMP Single Line Compute Constructs\n",
    "\n",
    "In this notebook, we will look at the use of single line directives as a means of moving the computation of a loop to the GPU.\n",
    "For the examples in this notebook, we will use a simple saxpy code, which we will discuss below.\n",
    "\n",
    "Let's begin, as ever, by checking that we have suitable GPUs available, moving into the source directory, and making sure that the working environment is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee9694-fa7b-402a-b6a4-530ea5ba2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocm-smi\n",
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2b-OpenMP_single_line_constructs/Fortran\n",
    "make clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1347ec-741e-4df8-a56b-f005a217b94a",
   "metadata": {},
   "source": [
    "## The saxpy code\n",
    "\n",
    "Saxpy is an acronym that stands for **Single precision A X plus Y**.\n",
    "It refers to the addition of two vectors, X and Y, where X is multiplied by a scalar A.\n",
    "Practically, this is done by looping over the elements of X and Y and calculating each result individually.\n",
    "Mathematically, it can be expressed as;\n",
    "$$z_i = a \\cdot x_i + y_i$$\n",
    "for the $i^{th}$ element of the arrays.\n",
    "\n",
    "These sorts of simple vector additions are used extensively in simulation and graphical processing, and can be written into code as a loop over the elements of the two arrays.\n",
    "Since each calculation has no dependence on any other element in the array, they could, in principle, all be carried out independently.\n",
    "This makes saxpy a prime candidate for parallelisation across CPUs and GPUs alike.\n",
    "Indeed, it is often colloquially referred to as the 'Hello, World!' of GPU programming, as the first real code example you are likely to write and run in any new GPU framework.\n",
    "\n",
    "Let's look now at a traditional CPU implementation of the saxpy code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d4a10-27f4-427c-9f4e-e4c82c6bf8ae",
   "metadata": {},
   "source": [
    "## CPU saxpy code\n",
    "\n",
    "[`saxpy_cpu.F90`](./Fortran/saxpy_cpu.F90) contains a basic implementation of saxpy code for a CPU.\n",
    "In the `main` block, we can see the instantiation and initialisation of the two arrays that we will be combining, `x` and `y`.\n",
    "The `saxpy` function then carries out the vector addition itself within the loop:\n",
    "```fortran\n",
    "   do i=1,n\n",
    "       y(i) = y(i) + a * x(i)\n",
    "   end do\n",
    "```\n",
    "Note that in this example, and others that you might see, rather than returning a new vector $z$, we are doing the addition directly into `y`.\n",
    "\n",
    "You should notice that we already have an OpenMP pragma in this code:\n",
    "```fortran\n",
    "!$ omp parallel for\n",
    "```\n",
    "This instructs the compiler to allow threaded parallelism of the loop on the CPU\n",
    "\n",
    "For our example, we initialise the `y` array to `2`, the `x` array to `1` and the scalar `a` to `2`, so we expect every element of the output array `y` after the computation to contain the value `4`.\n",
    "\n",
    "We can build this code using the `saxpy_cpu` option from the [`Makefile`](./Fortran/Makefile).\n",
    "Let's build and run it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb0557-4d60-4a1d-bb12-4e6f46340ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "make saxpy_cpu\n",
    "./saxpy_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94feda2-1643-442e-979e-6e88fd951f39",
   "metadata": {},
   "source": [
    "The code has run successfully with the expected output.\n",
    "\n",
    "Now, let's start changing the pragma instructions to offload our loop onto the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59687944-2b00-4a47-97d3-d1a0e2f9e853",
   "metadata": {},
   "source": [
    "## Offloading arrays to the GPU\n",
    "\n",
    "We will now go about moving our calculation to the GPU, starting with a simplified version of the code.\n",
    "\n",
    "### Automatically and dynamically assigned arrays\n",
    "\n",
    "The code in [`saxpy_gpu_singleunit_autoalloc.F90`](./Fortran/saxpy_gpu_singleunit_autoalloc.F90) contains a slightly altered version of the saxpy code.\n",
    "In it, `x` and `y` are assigned on the stack, so that the compiler is now fully aware of the array sizes that need to be moved in the following loop.\n",
    "Note that we've had to reduce the number of entries in the arrays in comparison to the previous example, to make sure we don't run out of memory on the stack.\n",
    "\n",
    "We can see that we've also now changed the OpenMP pragma instruction to:\n",
    "```Fortran\n",
    "!$omp target teams distribute parallel do\n",
    "```\n",
    "\n",
    "Let's remind ourselves of what the directives in this pragma are doing:\n",
    " - `target` tells the compiler to transfer control and data from the host (CPU) to the device (GPU),\n",
    " - `teams` creates a series of thread teams that can execute the code in parallel,\n",
    " - `distribute parallel do` instructs the compiler to run the subsequent `do` loop in parallel, distributing it between the previously created thread teams.\n",
    "\n",
    "Put all together, this commonly-used construct asks that the subsequent `do` loop block be run in parallel on the GPU.\n",
    "Let's try building and running this code now, using the `saxpy_gpu_singleunit_autoalloc` option of the [`Makefile`](./Fortran/Makefile).\n",
    "\n",
    "Remember that we can set the `LIBOMPTARGET_INFO` environment variable to report at runtime the data arguments passed to an OpenMP device kernel.\n",
    "In this way, we can ensure that we are correctly running on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13034e-3459-41df-9b98-1a8a2a133705",
   "metadata": {},
   "outputs": [],
   "source": [
    "export LIBOMPTARGET_INFO=1\n",
    "make saxpy_gpu_singleunit_autoalloc\n",
    "./saxpy_gpu_singleunit_autoalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a57e39-4e5c-4dc9-9fb9-2667576acaa5",
   "metadata": {},
   "source": [
    "Success!\n",
    "We've offloaded our saxpy loop to the GPU, and run the addition there in parallel.\n",
    "\n",
    "But what if we want to dynamically assign the size of the input arrays, rather than hard-code their sizes at the beginning of the code?\n",
    "In the example code [`saxpy_gpu_singleunit_dynamic.F90`](./Fortran/saxpy_gpu_singleunit_dynamic.F90), we've changed their assignment to `allocate` commands whilst keeping the rest of the code the same.\n",
    "\n",
    "This code can be built using the `saxpy_gpu_singleunit_dynamic` command, so let's build and run it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7dff2-4d69-4985-8c32-5a21f06f104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make saxpy_gpu_singleunit_dynamic\n",
    "./saxpy_gpu_singleunit_dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03d6e5-6661-4a33-97a3-a5b4f2dbee83",
   "metadata": {},
   "source": [
    "If you've also been following the C examples, you might notice that the additional environment variable `HSA_XNACK` - which allows the operating system to automatically move dynamically assigned data to the device - is not needed in this example.\n",
    "This is because of the way arrays are allocated in Fortran; they already contain enough information for the compiler to correctly offload them even without this feature enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d293d-4d10-4cae-8a4f-e9cd327b6865",
   "metadata": {},
   "source": [
    "### Moving the allocation to the main\n",
    "\n",
    "Now that we can offload our loop successfully, even for dynamically assigned arrays, let's return to the original example code.\n",
    "Here, we want to allocate our arrays in the `main` block, and pass them as-is to the saxpy subroutine.\n",
    "We will then keep the information calculated during the addition, rather than discarding it at the end of the subroutine's scope.\n",
    "This will have many more real-world applications than the previous examples.\n",
    "[`saxpy_gpu_paralleldo.F90`](./Fortran/saxpy_gpu_paralleldo.F90) shows how we can apply the new pragma in this way.\n",
    "\n",
    "Let's compile and run this code, using the `saxpy_gpu_paralleldo` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79199e-46bc-480b-ae26-af4be555bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "make saxpy_gpu_paralleldo\n",
    "./saxpy_gpu_paralleldo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40ad95-b8ad-4be4-9a6b-1394ea6b129e",
   "metadata": {},
   "source": [
    "This works as desired.\n",
    "\n",
    "Now let's look at some more pragma clauses that might prove useful for the saxpy example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb61d5-9ed2-4ef7-ae2b-81ac4e7cc21f",
   "metadata": {},
   "source": [
    "## The **loop** clause\n",
    "\n",
    "In more recent versions of OpenMP, the `loop` clause has been added as a simpler replacement to the `distribute parallel do` clause.\n",
    "The clause that we would need to write for our offloaded loop would then become:\n",
    "```Fortran\n",
    "!$omp target teams loop\n",
    "```\n",
    "\n",
    "This new clause simplifies our usual pragmas, and allows the compiler more freedom in its implementation of parallelism for the applicable loop.\n",
    "Indeed, ROCm will generate an optimised target region using this pragma over the traditional `distribute parallel do` clause for AMD GPUs.  Additionally, from OpenMP version 6.0 it has changed replace the `teams distribute parallel for` clause. At the time of writing, not many compilers support OpenMP version 6.0, however, you should be aware of this upcoming change and check the documentation for your compiler of choice.\n",
    "\n",
    "This construct does currently have drawbacks, however.\n",
    "Because it is relatively novel, not all compilers will support its applications, and the additional freedom that it affords the compilers may not yet be optimised for all available cards and scenarios.\n",
    "\n",
    "There is an example of the `loop` clause for our saxpy code in [`saxpy_gpu_loop.F90`](./Fortran/saxpy_gpu_loop.F90).  Let's compile and run it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e3afe-4fd6-42c5-b567-b90927ed1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "make saxpy_gpu_loop\n",
    "./saxpy_gpu_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac892f-0c48-485a-a9f0-58aaa987897b",
   "metadata": {},
   "source": [
    "We see that the performance is largely consistent with the previous examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e58bc-3a4e-4106-a2eb-0c487cb25f0e",
   "metadata": {},
   "source": [
    "## The **collapse** clause\n",
    "\n",
    "The final clause we will look at in this notebook is the `collapse(n)` clause.\n",
    "This clause requests that `n` nested loops be reduced (or 'collapsed') and executed as a single loop.\n",
    "\n",
    "We can see an example of this in the example code [`saxpy_gpu_collapse.F90`](./Fortran/saxpy_gpu_collapse.F90).\n",
    "Here, we have transformed `x` and `y` into 2D arrays, and are performing the saxpy operation with nested loops over these dimensions.\n",
    "The `collapse` clause is then added to the end of our normal pragma to request the reduction to one dimension.\n",
    "This clause is very useful when working with Fortran's multi-dimensional arrays.\n",
    "\n",
    "Let's build and run the code, using the `saxpy_gpu_collapse` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40429abd-8051-4fea-b709-067eb9081e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "make saxpy_gpu_collapse\n",
    "./saxpy_gpu_collapse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618f6b9-d814-4792-b593-f392897ca026",
   "metadata": {},
   "source": [
    "As we've seen in this notebook, it is very easy to add a single line pragma that offloads and runs a loop on a GPU.\n",
    "Dynamic memory options available on the recent MI200 and MI300 series AMD GPUs make managing the memory involved in the process much simpler, so that we can focus on parallelising the appropriate loops rather than fiddling with what memory needs to go where.\n",
    "\n",
    "In the next section, we will look at some more complex constructs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NI200",
   "language": "bash",
   "name": "ni200"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
