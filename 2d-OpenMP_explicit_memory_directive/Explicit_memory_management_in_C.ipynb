{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5e4617",
   "metadata": {},
   "source": [
    "# OpenMP Explicit Memory Management\n",
    "\n",
    "In this notebook, we will look at the explicit memory management directives available in OpenMP, and how to employ them to effectively optimise our code.\n",
    "In particular, we will be looking at how the `data` and `map` clauses are used to move memory between the host and device, and how `update` can be used to enforce copying.\n",
    "\n",
    "Let's begin in the usual manner; making sure we have a working GPU; loading in to the appropriate directory; and setting up a clean environment to work in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2668b-4085-4522-ab5a-1c1ff06a5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocm-smi\n",
    "cd $HOME/DiRAC-AMD-GPU/notebooks/02-OpenMP/2d-OpenMP_explicit_memory_directive/C\n",
    "export LD_LIBRARY_PATH=/usr/lib64:/$HOME/opt/lib:${LD_LIBRARY_PATH}\n",
    "make clean && rm -rf build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaad9f5",
   "metadata": {},
   "source": [
    "## Structured and unstructured regions\n",
    "\n",
    "Let us first look at an important concept in OpenMP, the code `region`.\n",
    "In OpenMP, a `region` is the section or block of code to which a pragma applies.\n",
    "\n",
    "OpenMP gives regions defined by different directives their own names;\n",
    " - Target regions are regions of code to be executed on the GPU,\n",
    " - Parallel regions are regions to be executed in parallel,\n",
    " - Data regions are code regions within which data may exists on the host and device.\n",
    "This notebook will primarily concern itself with data regions, though we will also want target regions to do real work on the GPU.\n",
    "\n",
    "Traditionally, and indeed by default, a `region` is the block of code that immediately follows an OpenMP directive.\n",
    "We've already seen this in the previous notebooks; the `for` loop immediately after a `#pragma omp target teams distribute parallel for` directive is the `region` in such a case.\n",
    "\n",
    "However, we don't need to be limited to just one statement in a region - indeed, in many cases that would be detrimental to performance!\n",
    "You might imagine a sequential series of operations being performed on the same set of vectors, for example - if each operation was treated as its own region, there would be a huge overhead incurred in unnecessary memory transfers between the host and device.\n",
    "If there was a way to tell the compiler that all of these operations were to be carried out on the device without the need to move any memory, we would surely see a marked improvement in performance.\n",
    "We can do this through the use of `structured regions`.\n",
    "\n",
    "### Structured data regions\n",
    "\n",
    "A structured region in OpenMP is a sequence of operations all intended to be carried out with a particular directive.\n",
    "They are defined by placing curly brackets `{ }` around the desired region, immediately after the OpenMP pragma that will govern its behaviour.\n",
    "\n",
    "We can see an example of this in [`target_data_structured.cpp`](./C/target_data_structured.cpp).\n",
    "What the particular clauses of the `#pragma omp target data` directive are doing will be discussed later in this notebook - for now it is enough to understand that the directive is applying to the subsequent 5 function calls contained within the curly brackets.\n",
    "It gives all of these calls access to the memory assigned on the device without further copies of the data from the host.\n",
    "Note that we can (and indeed must) issue further target directives in the `zeros` and `saxpy` functions in order to actually carry out the calculations on the device.\n",
    "\n",
    "Let's try compiling and running this now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3988450-0a6c-443a-9782-cb54258c50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "make target_data_structured\n",
    "./target_data_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364b43c-8583-4903-882d-6b8678393e89",
   "metadata": {},
   "source": [
    "A structured region is a powerful tool to run a set of operations on the device without incurring the overheads of transferring data.\n",
    "It does, however, have one major drawback: being defined by a set of curly brackets limits these structured regions to including only sequential commands.\n",
    "\n",
    "We can imagine a scenario in which it would be beneficial to have an array allocated on the device and stay there whilst other, unrelated, operations are going on.\n",
    "A C++ class might contain a member array, for example, that we want to manipulate using different method calls at different times.\n",
    "If we then wanted to accelerate these calculations on the device with a structured region, it would likely end up with us copying the array backwards and forwards between host and device many times.\n",
    "We might hope that there would be a better way to do such calculations, and good news - in more recent versions of the OpenMP standard, there is!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba15dd",
   "metadata": {},
   "source": [
    "### Unstructured data regions\n",
    "\n",
    "An unstructured data region is an area of code within which data is allocated onto a device.\n",
    "Unlike a structured region, this area of code does not need to be sequential or contained within curly brackets.\n",
    "\n",
    "We define these regions using the `enter` and `exit` clauses with the `#pragma omp target data` directive.\n",
    "Typically, the `target enter data` directive is issued immediated after allocation - often in the constructor of an object with data targeted for the device.\n",
    "The matching `target exit data` directive will then be just before the associated `free`, often in an object's destructor.\n",
    "\n",
    "[`target_data_unstructured.cpp`](./C/target_data_unstructured.cpp) shows an example of an unstructured data region.\n",
    "This example executes the same calculations as [`target_data_structured.cpp`](./C/target_data_structured.cpp), but using variables that are defined out of scope of the OpenMP data directives.\n",
    "As these variables are not passed to the `compute` function as arguments, we need to use an unstructured data region approach to the memory management here.\n",
    "We allocate the necessary variables in `main`, then begin the unstructured region with the `target enter data` directive.\n",
    "The calculations within `compute` then use the variables that have been declared on the device, before leaving the unstructured region with `target exit data` and freeing the resources.\n",
    "\n",
    "Let's compile and run it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e387609-dd42-4604-9b42-891db6bf0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "make target_data_unstructured\n",
    "./target_data_unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04664a9b",
   "metadata": {},
   "source": [
    "## The `map` clause\n",
    "\n",
    "Now that we understand the concept of a region in OpenMP, let's look in more detail at how we allocate and transfer data in them.\n",
    "\n",
    "When we enter a data region (either structured or unstructured) using the `#pragma omp target data` directive, we must also supply a `map` clause that tells the compiler which data we are transferring to the device, and how it should be handled.\n",
    "The `map` syntax follows the following convention:\n",
    "\n",
    "```C++\n",
    "map ([map-type:] var_list)\n",
    "```\n",
    "where `var_list` is a list of the variables to be mapped to the device.\n",
    "The available `map-type`s are:\n",
    " - `to` - On entering the data region, transfer the contents of the `var_list` items from the host to the device,\n",
    " - `from` - On leaving the data region, transfer the contents of the `var_list` items from the device to the host,\n",
    " - `tofrom` - On entering the data region, transfer the contents of the `var_list` items from the host to the device, and on leaving the region transfer it back from the device to the host,\n",
    " - `alloc` - On entering the data region, initalise the `var_list` items with an undefined initial value,\n",
    " - `delete` - deletes the allocated `var_list` items from the device,\n",
    " - `release` - decrements the reference count to the `var_list` items by one, and deletes the allocation if this number reaches zero. This is useful if multiple data regions access the same memory.\n",
    "\n",
    "If no `map-type` is supplied, `map` will default to `tofrom` behaviour.\n",
    "Only one `map-type` can be provided per `map` clause, but multiple `map` clauses can be given to each `target data` directive when different data should be treated differently, as seen in the [`target_data_structured.cpp`](./C/target_data_structured.cpp) example.\n",
    "\n",
    "It should be noted that the compiler has no way of immediately knowing the size of an array passed in the `var_list` to a `map` clause.\n",
    "For this reason, we must supply the size of the array in the form `array[start:end]`, as demonstrated in the previous examples.\n",
    "\n",
    "Note also that a `map` clause does not have to be associated with a `target data` directive - parallel and target regions can also include `map` clauses if the transfer of data is only required for those particular directives.\n",
    "\n",
    "The `map` clause directs data transfers between the host and device at the beginning and end of a data region, but does not provide any further links between these data regions than that.\n",
    "There are effectively now two copies of the data - one on the host, and one on the device - that can be operated on independently, and have no immediate bearing on each other.\n",
    "This could potentially be problematic if we want to carry out a CPU-based calculation on a variable mapped to the device part way through a data region, and then use this value in a device-based operation.\n",
    "\n",
    "We could overcome this problem by closing a data region whenever we need to carry out work on the host, and then declaring a new region with the changed variables, but the additional overheads associated with data transfer and memory allocation with each region declaration make this an inefficient approach.\n",
    "\n",
    "Fortunately, there exists in OpenMP a feature that allows the transfer of data within a data region, in the form of the `update` directive.\n",
    "\n",
    "## The update directive\n",
    "\n",
    "The `#pragma omp target update` directive tells the compiler to transfer data between the host and device.\n",
    "No memory allocation or freeing is allowed with this directive, it is strictly to update variables already declared on the device within a data region.\n",
    "It can take the following additional clauses:\n",
    " - `device(int)` - an integer identifier of the acceleration device with which to update,\n",
    " - `to(var_list)` - a list of variables to update from host to device,\n",
    " - `from(var_list)` - a list of variables to update from device to host,\n",
    " - `if(expression)` - run the pragma only if the expression is true.\n",
    "Note that the `to` and `from` clauses can take subarrays of the variables being transferred, so that we can update only the necessary parts of our offloaded variables and save transfer time for larger arrays.\n",
    "\n",
    "[`target_data_update.cpp`](./C/target_data_update.cpp) shows an example of an `update` directive in use.\n",
    "In `main`, we declare a structured data region that allocates `tmp` and maps `input` and `res` to the device.\n",
    "We carry out `some_computation` on the target device, which uses values of `input` to fill `tmp`.\n",
    "We then call `update_input_array_on_the_host`, which - as its name suggests - updates the values of `input` on the host.\n",
    "\n",
    "At this point, `input` has changed on the host, but not on the device.\n",
    "We want to call the `final_calcutation` function, and carry it out as a calculation on the target device, but this takes `input` as an argument.\n",
    "If we were to immediately call it, the function would take the values of `input` that already exist on the device, which have not been updated since the host calculation.\n",
    "To use these updated values of `input`, we insert a `#pragma omp target update to(input[:N])` directive before calling the `final_calculation`.\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f3343-fd6b-46ba-840f-f21cae115af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make target_data_update\n",
    "./target_data_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec7419",
   "metadata": {},
   "source": [
    "## Memory pragma examples\n",
    "\n",
    "Now that we understand OpenMP regions, and the `map` and `update` commands do, we can look at some examples of how to use them for explicit memory management in our own code.\n",
    "\n",
    "Let's begin by setting up our environment.\n",
    "We'll set `LIBOMPTARGET_INFO` as before to check information about our OpenMP offloading, but this time we'll also introduce a new environmental variable; `OMP_TARGET_OFFLOAD=MANDATORY`.\n",
    "This will terminate the program if the code fails to offload execution to the device, rather than falling back on the host.\n",
    "Once these are set, we'll build the available code for the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16f61a-7918-4d35-83d8-250cad76b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "export LIBOMPTARGET_INFO=0\n",
    "export OMP_TARGET_OFFLOAD=MANDATORY\n",
    "cmake -B build\n",
    "cmake --build build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab5e74",
   "metadata": {},
   "source": [
    "### The daxpy example code - `mem1.cc`\n",
    "\n",
    "[`mem1.cc`](./C/mem1.cc) contains the base version of the code that we will be modifying in this notebook.\n",
    "It is a simple daxpy code - that is, the same as the saxpy code we've been using up until now, but at double precision - that carries out one operation on the device and calculates the time taken to do so.\n",
    "Let's look at the OpenMP directives we're using in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c07064-ca65-4d8f-924c-77ab55d88fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grep \"pragma omp\" mem1.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9f1b5",
   "metadata": {},
   "source": [
    "As you can see, we only have one OpenMP pragma in the base version of the code.\n",
    "The usual `#pragma omp target teams distribute parallel for` directive has been given a `map` clause to direct the memory transfers between the host and device for the following calculation.\n",
    "We are mapping our inputs `x` and `y` to the host at the beginning of the operation, and then reading off the result `z` upon completion.\n",
    "\n",
    "Let's see it in operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c95088-d0f1-4f9d-8402-cf867eef96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "./build/mem1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c41b3",
   "metadata": {},
   "source": [
    "### Adding an unstructured data region - `mem2.cc`\n",
    "\n",
    "Let's compare the base example with [`mem2.cc`](./C/mem2.cc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fd9d3-d393-41ca-930e-85418651a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff --unified mem1.cc mem2.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b753bdc",
   "metadata": {},
   "source": [
    "We've added in a `target enter data` directive immediately after assignment, and a `target exit data` directive just before we delete our variables.\n",
    "In this way, we've defined an unstructured data region that ensures that our variables `x`, `y` and `z` will all be on the device.\n",
    "\n",
    "We've also added in the `always` keyword to the `map` clause in the `daxpy` function - this tells the compiler to ensure data is transfered between the host and device in the specified way at this point.\n",
    "Without this additional keyword, updates to the variables declared in our data region might not be transfered across as expected.\n",
    "\n",
    "Let's see how this version of the code performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ed16f-01a5-4d71-82b7-d937f9b9f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "./build/mem2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb39daa",
   "metadata": {},
   "source": [
    "We can see that the performance of the code is largely comparable to the structured example.\n",
    "\n",
    "### Replacing `map to/from` with `update` directives - `mem3.cc`\n",
    "\n",
    "Let's compare [`mem3.cc`](./C/mem3.cc) with the baseline code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dba365-a5a9-43fa-b4a7-880ce02c0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff --unified mem1.cc mem3.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa1f76",
   "metadata": {},
   "source": [
    "In addition to the changes we made in [`mem2.cc`](./C/mem2.cc), we have now also removed the data transfers from the loop directive.\n",
    "Instead, we've replaced them with `update` directives that more efficiently handle the data transfers.\n",
    "\n",
    "Let's compare the performance now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b0db9-549e-44af-822b-e93e6e0311fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "./build/mem3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b22ba7c",
   "metadata": {},
   "source": [
    "Again, we see the performance is comparable to the original example.\n",
    "\n",
    "### Replacing `delete` with `release` to use reference counting - `mem4.cc`\n",
    "\n",
    "Let's compare the next example, [`mem4.cc`](./C/mem4.cc), with the first unstructured data region code, [`mem2.cc`](./C/mem2.cc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0ef7d-eaf3-4e51-a831-4f2b44f47fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff --unified mem2.cc mem4.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59843a74",
   "metadata": {},
   "source": [
    "The only difference here is that we have replaced the `delete` directive with a `release`, to allow the use of reference counting for our resources.\n",
    "As we are only using the relevant variables once in our code, this will decrement the reference counter for them to zero, and act as a `delete` option.\n",
    "\n",
    "Let's run this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1aabd-e65d-4347-a458-a0a7514a90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "./build/mem4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5039d83",
   "metadata": {},
   "source": [
    "### Reducing the number of data transfers with the use of to/from - `mem5.cc`\n",
    "\n",
    "Let's compare our final example, [`mem5.cc`](./C/mem5.cc), with our baseline unstructured data region code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc5b39-39a9-472a-a38e-6710b04907c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff --unified mem2.cc mem5.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2932b0",
   "metadata": {},
   "source": [
    "In this example, we are trying to minimise the number of data transfers in our code.\n",
    "To this end, we have changed the initial data region to `map(to)` for `x` and `y`, to transfer their initial assigned values immediately at allocation.\n",
    "The result, `z`, is only allocated here, as it does not need any initial values.\n",
    "\n",
    "We have then removed the `always` keyword from the target loop, as we no longer want a data transfer to occur here.\n",
    "Finally, we then carry out the transfer back from `z` only as we leave the data region.\n",
    "In this way, we only have to transfer the values of each variable exactly once. \n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9162a7-bde3-465a-ac84-d2966bb2f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "./build/mem5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b80fd",
   "metadata": {},
   "source": [
    "We observe similar performance to the baseline case, perhaps with a slight improvement in performance.\n",
    "With such small examples, performance improvements will be difficult to spot.\n",
    "Feel free to experiment with the example code, changing the size of the array or complexity of calculations, and see how the performance changes with the use of different memory pragmas.\n",
    "\n",
    "Now that we've learnt how to manage memory explicitly ourselves with OpenMP directives, we can look at how to let the operating system handle the memory for us.\n",
    "In the next notebook, we will be exploring this by using Managed Memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NI200",
   "language": "bash",
   "name": "ni200"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
